{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch-VGG-ONNX-Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use PyTorch pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import os\n",
    "\n",
    "# Use an existing model from Torchvision, note it \n",
    "# will download this if not already on your computer (might take time)\n",
    "net = models.vgg16(pretrained=True)\n",
    "net.eval()\n",
    "\n",
    "# Create some sample input in the shape this model expects\n",
    "dummy_input = torch.ones(10, 3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%0 : Float(10, 3, 224, 224)\n",
      "      %1 : Float(64, 3, 3, 3)\n",
      "      %2 : Float(64)\n",
      "      %3 : Float(64, 64, 3, 3)\n",
      "      %4 : Float(64)\n",
      "      %5 : Float(128, 64, 3, 3)\n",
      "      %6 : Float(128)\n",
      "      %7 : Float(128, 128, 3, 3)\n",
      "      %8 : Float(128)\n",
      "      %9 : Float(256, 128, 3, 3)\n",
      "      %10 : Float(256)\n",
      "      %11 : Float(256, 256, 3, 3)\n",
      "      %12 : Float(256)\n",
      "      %13 : Float(256, 256, 3, 3)\n",
      "      %14 : Float(256)\n",
      "      %15 : Float(512, 256, 3, 3)\n",
      "      %16 : Float(512)\n",
      "      %17 : Float(512, 512, 3, 3)\n",
      "      %18 : Float(512)\n",
      "      %19 : Float(512, 512, 3, 3)\n",
      "      %20 : Float(512)\n",
      "      %21 : Float(512, 512, 3, 3)\n",
      "      %22 : Float(512)\n",
      "      %23 : Float(512, 512, 3, 3)\n",
      "      %24 : Float(512)\n",
      "      %25 : Float(512, 512, 3, 3)\n",
      "      %26 : Float(512)\n",
      "      %27 : Float(4096, 25088)\n",
      "      %28 : Float(4096)\n",
      "      %29 : Float(4096, 4096)\n",
      "      %30 : Float(4096)\n",
      "      %31 : Float(1000, 4096)\n",
      "      %32 : Float(1000)) {\n",
      "  %33 : Float(10, 64, 224, 224) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%0, %1, %2), scope: VGG/Sequential[features]/Conv2d[0]\n",
      "  %34 : Float(10, 64, 224, 224) = onnx::Relu(%33), scope: VGG/Sequential[features]/ReLU[1]\n",
      "  %35 : Float(10, 64, 224, 224) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%34, %3, %4), scope: VGG/Sequential[features]/Conv2d[2]\n",
      "  %36 : Float(10, 64, 224, 224) = onnx::Relu(%35), scope: VGG/Sequential[features]/ReLU[3]\n",
      "  %37 : Float(10, 64, 112, 112) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%36), scope: VGG/Sequential[features]/MaxPool2d[4]\n",
      "  %38 : Float(10, 128, 112, 112) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%37, %5, %6), scope: VGG/Sequential[features]/Conv2d[5]\n",
      "  %39 : Float(10, 128, 112, 112) = onnx::Relu(%38), scope: VGG/Sequential[features]/ReLU[6]\n",
      "  %40 : Float(10, 128, 112, 112) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%39, %7, %8), scope: VGG/Sequential[features]/Conv2d[7]\n",
      "  %41 : Float(10, 128, 112, 112) = onnx::Relu(%40), scope: VGG/Sequential[features]/ReLU[8]\n",
      "  %42 : Float(10, 128, 56, 56) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%41), scope: VGG/Sequential[features]/MaxPool2d[9]\n",
      "  %43 : Float(10, 256, 56, 56) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%42, %9, %10), scope: VGG/Sequential[features]/Conv2d[10]\n",
      "  %44 : Float(10, 256, 56, 56) = onnx::Relu(%43), scope: VGG/Sequential[features]/ReLU[11]\n",
      "  %45 : Float(10, 256, 56, 56) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%44, %11, %12), scope: VGG/Sequential[features]/Conv2d[12]\n",
      "  %46 : Float(10, 256, 56, 56) = onnx::Relu(%45), scope: VGG/Sequential[features]/ReLU[13]\n",
      "  %47 : Float(10, 256, 56, 56) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%46, %13, %14), scope: VGG/Sequential[features]/Conv2d[14]\n",
      "  %48 : Float(10, 256, 56, 56) = onnx::Relu(%47), scope: VGG/Sequential[features]/ReLU[15]\n",
      "  %49 : Float(10, 256, 28, 28) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%48), scope: VGG/Sequential[features]/MaxPool2d[16]\n",
      "  %50 : Float(10, 512, 28, 28) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%49, %15, %16), scope: VGG/Sequential[features]/Conv2d[17]\n",
      "  %51 : Float(10, 512, 28, 28) = onnx::Relu(%50), scope: VGG/Sequential[features]/ReLU[18]\n",
      "  %52 : Float(10, 512, 28, 28) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%51, %17, %18), scope: VGG/Sequential[features]/Conv2d[19]\n",
      "  %53 : Float(10, 512, 28, 28) = onnx::Relu(%52), scope: VGG/Sequential[features]/ReLU[20]\n",
      "  %54 : Float(10, 512, 28, 28) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%53, %19, %20), scope: VGG/Sequential[features]/Conv2d[21]\n",
      "  %55 : Float(10, 512, 28, 28) = onnx::Relu(%54), scope: VGG/Sequential[features]/ReLU[22]\n",
      "  %56 : Float(10, 512, 14, 14) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%55), scope: VGG/Sequential[features]/MaxPool2d[23]\n",
      "  %57 : Float(10, 512, 14, 14) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%56, %21, %22), scope: VGG/Sequential[features]/Conv2d[24]\n",
      "  %58 : Float(10, 512, 14, 14) = onnx::Relu(%57), scope: VGG/Sequential[features]/ReLU[25]\n",
      "  %59 : Float(10, 512, 14, 14) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%58, %23, %24), scope: VGG/Sequential[features]/Conv2d[26]\n",
      "  %60 : Float(10, 512, 14, 14) = onnx::Relu(%59), scope: VGG/Sequential[features]/ReLU[27]\n",
      "  %61 : Float(10, 512, 14, 14) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%60, %25, %26), scope: VGG/Sequential[features]/Conv2d[28]\n",
      "  %62 : Float(10, 512, 14, 14) = onnx::Relu(%61), scope: VGG/Sequential[features]/ReLU[29]\n",
      "  %63 : Float(10, 512, 7, 7) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%62), scope: VGG/Sequential[features]/MaxPool2d[30]\n",
      "  %64 : Long() = onnx::Constant[value={0}]()\n",
      "  %65 : Dynamic = onnx::Shape(%63), scope: VGG\n",
      "  %66 : Long() = onnx::Gather[axis=0](%65, %64), scope: VGG\n",
      "  %67 : Long() = onnx::Constant[value={-1}]()\n",
      "  %68 : Dynamic = onnx::Unsqueeze[axes=[0]](%66), scope: VGG\n",
      "  %69 : Dynamic = onnx::Unsqueeze[axes=[0]](%67), scope: VGG\n",
      "  %70 : int[] = onnx::Concat[axis=0](%68, %69), scope: VGG\n",
      "  %71 : Float(10, 25088) = onnx::Reshape(%63, %70), scope: VGG\n",
      "  %72 : Dynamic = onnx::Constant[value={0}]()\n",
      "  %73 : Dynamic = onnx::Gemm[alpha=1, beta=0, transB=1](%71, %27, %72)\n",
      "  %74 : Float(10, 4096) = onnx::Add(%28, %73)\n",
      "  %75 : Float(10, 4096) = onnx::Relu(%74), scope: VGG/Sequential[classifier]/ReLU[1]\n",
      "  %76 : Float(10, 4096), %77 : Dynamic = onnx::Dropout[ratio=0.5](%75), scope: VGG/Sequential[classifier]/Dropout[2]\n",
      "  %78 : Dynamic = onnx::Constant[value={0}]()\n",
      "  %79 : Dynamic = onnx::Gemm[alpha=1, beta=0, transB=1](%76, %29, %78)\n",
      "  %80 : Float(10, 4096) = onnx::Add(%30, %79)\n",
      "  %81 : Float(10, 4096) = onnx::Relu(%80), scope: VGG/Sequential[classifier]/ReLU[4]\n",
      "  %82 : Float(10, 4096), %83 : Dynamic = onnx::Dropout[ratio=0.5](%81), scope: VGG/Sequential[classifier]/Dropout[5]\n",
      "  %84 : Dynamic = onnx::Constant[value={0}]()\n",
      "  %85 : Dynamic = onnx::Gemm[alpha=1, beta=0, transB=1](%82, %31, %84)\n",
      "  %86 : Float(10, 1000) = onnx::Add(%32, %85)\n",
      "  return (%86);\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if not os.path.isdir(\"model\"):\n",
    "    os.mkdir(\"model\")\n",
    "\n",
    "model_name = \"pytorch_vgg.onnx\"\n",
    "model_path = os.path.join(\"model\", model_name)\n",
    "torch.onnx.export(net, \n",
    "                  dummy_input, \n",
    "                  model_path, \n",
    "                  verbose=True,\n",
    "                  export_params=True\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the ONNX model to Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/onnx_tf/common/__init__.py:87: UserWarning: FrontendHandler.get_outputs_names is deprecated. It will be removed in future release.. Use node.outputs instead.\n",
      "  warnings.warn(message)\n",
      "/usr/local/lib/python3.5/dist-packages/onnx_tf/common/handler_helper.py:73: UserWarning: Unknown op Asinh in domain `ai.onnx`.\n",
      "  handler.ONNX_OP, handler.DOMAIN or \"ai.onnx\"))\n",
      "/usr/local/lib/python3.5/dist-packages/onnx_tf/common/handler_helper.py:73: UserWarning: Unknown op Cosh in domain `ai.onnx`.\n",
      "  handler.ONNX_OP, handler.DOMAIN or \"ai.onnx\"))\n",
      "/usr/local/lib/python3.5/dist-packages/onnx_tf/common/handler_helper.py:73: UserWarning: Unknown op Sinh in domain `ai.onnx`.\n",
      "  handler.ONNX_OP, handler.DOMAIN or \"ai.onnx\"))\n",
      "/usr/local/lib/python3.5/dist-packages/onnx_tf/common/handler_helper.py:73: UserWarning: Unknown op Atanh in domain `ai.onnx`.\n",
      "  handler.ONNX_OP, handler.DOMAIN or \"ai.onnx\"))\n",
      "/usr/local/lib/python3.5/dist-packages/onnx_tf/common/handler_helper.py:73: UserWarning: Unknown op Acosh in domain `ai.onnx`.\n",
      "  handler.ONNX_OP, handler.DOMAIN or \"ai.onnx\"))\n",
      "/usr/local/lib/python3.5/dist-packages/onnx_tf/common/handler_helper.py:73: UserWarning: Unknown op Compress in domain `ai.onnx`.\n",
      "  handler.ONNX_OP, handler.DOMAIN or \"ai.onnx\"))\n",
      "/usr/local/lib/python3.5/dist-packages/onnx_tf/common/handler_helper.py:73: UserWarning: Unknown op DynamicSlice in domain `ai.onnx`.\n",
      "  handler.ONNX_OP, handler.DOMAIN or \"ai.onnx\"))\n",
      "/usr/local/lib/python3.5/dist-packages/onnx_tf/common/handler_helper.py:73: UserWarning: Unknown op ConstantLike in domain `ai.onnx`.\n",
      "  handler.ONNX_OP, handler.DOMAIN or \"ai.onnx\"))\n",
      "/usr/local/lib/python3.5/dist-packages/onnx_tf/common/handler_helper.py:73: UserWarning: Unknown op EyeLike in domain `ai.onnx`.\n",
      "  handler.ONNX_OP, handler.DOMAIN or \"ai.onnx\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/onnx_tf/handlers/backend/reshape.py:31: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "\n",
    "# Load the ONNX file\n",
    "model = onnx.load(\"model/pytorch_vgg.onnx\")\n",
    "\n",
    "# Import the ONNX model to Tensorflow\n",
    "tf_rep = prepare(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported model has been executed on TF backend, and the result looks good!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "tf_out = tf_rep.run(dummy_input.numpy())\n",
    "torch_out = net(dummy_input).detach().numpy()\n",
    "\n",
    "np.testing.assert_almost_equal(tf_out[0], \n",
    "                               torch_out, \n",
    "                               decimal=3\n",
    "                              )\n",
    "\n",
    "print(\"Exported model has been executed on TF backend, and the result looks good!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
