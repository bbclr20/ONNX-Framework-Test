{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch-Squeezenet-ONNX-Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use PyTorch pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import os\n",
    "\n",
    "# Use an existing model from Torchvision, note it \n",
    "# will download this if not already on your computer (might take time)\n",
    "net = models.squeezenet1_0(pretrained=True)\n",
    "net.eval()\n",
    "\n",
    "# Create some sample input in the shape this model expects\n",
    "dummy_input = torch.ones(10, 3, 224, 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!! fail to export max_pool2d_with_indices because ceil_mode not supported !! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%0 : Float(10, 3, 224, 224)\n",
      "      %1 : Float(96, 3, 7, 7)\n",
      "      %2 : Float(96)\n",
      "      %3 : Float(16, 96, 1, 1)\n",
      "      %4 : Float(16)\n",
      "      %5 : Float(64, 16, 1, 1)\n",
      "      %6 : Float(64)\n",
      "      %7 : Float(64, 16, 3, 3)\n",
      "      %8 : Float(64)\n",
      "      %9 : Float(16, 128, 1, 1)\n",
      "      %10 : Float(16)\n",
      "      %11 : Float(64, 16, 1, 1)\n",
      "      %12 : Float(64)\n",
      "      %13 : Float(64, 16, 3, 3)\n",
      "      %14 : Float(64)\n",
      "      %15 : Float(32, 128, 1, 1)\n",
      "      %16 : Float(32)\n",
      "      %17 : Float(128, 32, 1, 1)\n",
      "      %18 : Float(128)\n",
      "      %19 : Float(128, 32, 3, 3)\n",
      "      %20 : Float(128)\n",
      "      %21 : Float(32, 256, 1, 1)\n",
      "      %22 : Float(32)\n",
      "      %23 : Float(128, 32, 1, 1)\n",
      "      %24 : Float(128)\n",
      "      %25 : Float(128, 32, 3, 3)\n",
      "      %26 : Float(128)\n",
      "      %27 : Float(48, 256, 1, 1)\n",
      "      %28 : Float(48)\n",
      "      %29 : Float(192, 48, 1, 1)\n",
      "      %30 : Float(192)\n",
      "      %31 : Float(192, 48, 3, 3)\n",
      "      %32 : Float(192)\n",
      "      %33 : Float(48, 384, 1, 1)\n",
      "      %34 : Float(48)\n",
      "      %35 : Float(192, 48, 1, 1)\n",
      "      %36 : Float(192)\n",
      "      %37 : Float(192, 48, 3, 3)\n",
      "      %38 : Float(192)\n",
      "      %39 : Float(64, 384, 1, 1)\n",
      "      %40 : Float(64)\n",
      "      %41 : Float(256, 64, 1, 1)\n",
      "      %42 : Float(256)\n",
      "      %43 : Float(256, 64, 3, 3)\n",
      "      %44 : Float(256)\n",
      "      %45 : Float(64, 512, 1, 1)\n",
      "      %46 : Float(64)\n",
      "      %47 : Float(256, 64, 1, 1)\n",
      "      %48 : Float(256)\n",
      "      %49 : Float(256, 64, 3, 3)\n",
      "      %50 : Float(256)\n",
      "      %51 : Float(1000, 512, 1, 1)\n",
      "      %52 : Float(1000)) {\n",
      "  %53 : Float(10, 96, 109, 109) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 7], pads=[0, 0, 0, 0], strides=[2, 2]](%0, %1, %2), scope: SqueezeNet/Sequential[features]/Conv2d[0]\n",
      "  %54 : Float(10, 96, 109, 109) = onnx::Relu(%53), scope: SqueezeNet/Sequential[features]/ReLU[1]\n",
      "  %55 : int[] = onnx::Constant[value= 3  3 [ CPULongType{2} ]]()\n",
      "  %56 : int[] = onnx::Constant[value= 2  2 [ CPULongType{2} ]]()\n",
      "  %57 : int[] = onnx::Constant[value= 0  0 [ CPULongType{2} ]]()\n",
      "  %58 : int[] = onnx::Constant[value= 1  1 [ CPULongType{2} ]]()\n",
      "  %59 : Long() = onnx::Constant[value={1}]()\n",
      "  %60 : Float(10, 96, 54, 54), %61 : Long(10, 96, 54, 54) = aten::max_pool2d_with_indices(%54, %55, %56, %57, %58, %59), scope: SqueezeNet/Sequential[features]/MaxPool2d[2]\n",
      "  %62 : Float(10, 16, 54, 54) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%60, %3, %4), scope: SqueezeNet/Sequential[features]/Fire[3]/Conv2d[squeeze]\n",
      "  %63 : Float(10, 16, 54, 54) = onnx::Relu(%62), scope: SqueezeNet/Sequential[features]/Fire[3]/ReLU[squeeze_activation]\n",
      "  %64 : Float(10, 64, 54, 54) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%63, %5, %6), scope: SqueezeNet/Sequential[features]/Fire[3]/Conv2d[expand1x1]\n",
      "  %65 : Float(10, 64, 54, 54) = onnx::Relu(%64), scope: SqueezeNet/Sequential[features]/Fire[3]/ReLU[expand1x1_activation]\n",
      "  %66 : Float(10, 64, 54, 54) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%63, %7, %8), scope: SqueezeNet/Sequential[features]/Fire[3]/Conv2d[expand3x3]\n",
      "  %67 : Float(10, 64, 54, 54) = onnx::Relu(%66), scope: SqueezeNet/Sequential[features]/Fire[3]/ReLU[expand3x3_activation]\n",
      "  %68 : Float(10, 128, 54, 54) = onnx::Concat[axis=1](%65, %67), scope: SqueezeNet/Sequential[features]/Fire[3]\n",
      "  %69 : Float(10, 16, 54, 54) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%68, %9, %10), scope: SqueezeNet/Sequential[features]/Fire[4]/Conv2d[squeeze]\n",
      "  %70 : Float(10, 16, 54, 54) = onnx::Relu(%69), scope: SqueezeNet/Sequential[features]/Fire[4]/ReLU[squeeze_activation]\n",
      "  %71 : Float(10, 64, 54, 54) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%70, %11, %12), scope: SqueezeNet/Sequential[features]/Fire[4]/Conv2d[expand1x1]\n",
      "  %72 : Float(10, 64, 54, 54) = onnx::Relu(%71), scope: SqueezeNet/Sequential[features]/Fire[4]/ReLU[expand1x1_activation]\n",
      "  %73 : Float(10, 64, 54, 54) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%70, %13, %14), scope: SqueezeNet/Sequential[features]/Fire[4]/Conv2d[expand3x3]\n",
      "  %74 : Float(10, 64, 54, 54) = onnx::Relu(%73), scope: SqueezeNet/Sequential[features]/Fire[4]/ReLU[expand3x3_activation]\n",
      "  %75 : Float(10, 128, 54, 54) = onnx::Concat[axis=1](%72, %74), scope: SqueezeNet/Sequential[features]/Fire[4]\n",
      "  %76 : Float(10, 32, 54, 54) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%75, %15, %16), scope: SqueezeNet/Sequential[features]/Fire[5]/Conv2d[squeeze]\n",
      "  %77 : Float(10, 32, 54, 54) = onnx::Relu(%76), scope: SqueezeNet/Sequential[features]/Fire[5]/ReLU[squeeze_activation]\n",
      "  %78 : Float(10, 128, 54, 54) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%77, %17, %18), scope: SqueezeNet/Sequential[features]/Fire[5]/Conv2d[expand1x1]\n",
      "  %79 : Float(10, 128, 54, 54) = onnx::Relu(%78), scope: SqueezeNet/Sequential[features]/Fire[5]/ReLU[expand1x1_activation]\n",
      "  %80 : Float(10, 128, 54, 54) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%77, %19, %20), scope: SqueezeNet/Sequential[features]/Fire[5]/Conv2d[expand3x3]\n",
      "  %81 : Float(10, 128, 54, 54) = onnx::Relu(%80), scope: SqueezeNet/Sequential[features]/Fire[5]/ReLU[expand3x3_activation]\n",
      "  %82 : Float(10, 256, 54, 54) = onnx::Concat[axis=1](%79, %81), scope: SqueezeNet/Sequential[features]/Fire[5]\n",
      "  %83 : int[] = onnx::Constant[value= 3  3 [ CPULongType{2} ]]()\n",
      "  %84 : int[] = onnx::Constant[value= 2  2 [ CPULongType{2} ]]()\n",
      "  %85 : int[] = onnx::Constant[value= 0  0 [ CPULongType{2} ]]()\n",
      "  %86 : int[] = onnx::Constant[value= 1  1 [ CPULongType{2} ]]()\n",
      "  %87 : Long() = onnx::Constant[value={1}]()\n",
      "  %88 : Float(10, 256, 27, 27), %89 : Long(10, 256, 27, 27) = aten::max_pool2d_with_indices(%82, %83, %84, %85, %86, %87), scope: SqueezeNet/Sequential[features]/MaxPool2d[6]\n",
      "  %90 : Float(10, 32, 27, 27) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%88, %21, %22), scope: SqueezeNet/Sequential[features]/Fire[7]/Conv2d[squeeze]\n",
      "  %91 : Float(10, 32, 27, 27) = onnx::Relu(%90), scope: SqueezeNet/Sequential[features]/Fire[7]/ReLU[squeeze_activation]\n",
      "  %92 : Float(10, 128, 27, 27) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%91, %23, %24), scope: SqueezeNet/Sequential[features]/Fire[7]/Conv2d[expand1x1]\n",
      "  %93 : Float(10, 128, 27, 27) = onnx::Relu(%92), scope: SqueezeNet/Sequential[features]/Fire[7]/ReLU[expand1x1_activation]\n",
      "  %94 : Float(10, 128, 27, 27) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%91, %25, %26), scope: SqueezeNet/Sequential[features]/Fire[7]/Conv2d[expand3x3]\n",
      "  %95 : Float(10, 128, 27, 27) = onnx::Relu(%94), scope: SqueezeNet/Sequential[features]/Fire[7]/ReLU[expand3x3_activation]\n",
      "  %96 : Float(10, 256, 27, 27) = onnx::Concat[axis=1](%93, %95), scope: SqueezeNet/Sequential[features]/Fire[7]\n",
      "  %97 : Float(10, 48, 27, 27) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%96, %27, %28), scope: SqueezeNet/Sequential[features]/Fire[8]/Conv2d[squeeze]\n",
      "  %98 : Float(10, 48, 27, 27) = onnx::Relu(%97), scope: SqueezeNet/Sequential[features]/Fire[8]/ReLU[squeeze_activation]\n",
      "  %99 : Float(10, 192, 27, 27) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%98, %29, %30), scope: SqueezeNet/Sequential[features]/Fire[8]/Conv2d[expand1x1]\n",
      "  %100 : Float(10, 192, 27, 27) = onnx::Relu(%99), scope: SqueezeNet/Sequential[features]/Fire[8]/ReLU[expand1x1_activation]\n",
      "  %101 : Float(10, 192, 27, 27) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%98, %31, %32), scope: SqueezeNet/Sequential[features]/Fire[8]/Conv2d[expand3x3]\n",
      "  %102 : Float(10, 192, 27, 27) = onnx::Relu(%101), scope: SqueezeNet/Sequential[features]/Fire[8]/ReLU[expand3x3_activation]\n",
      "  %103 : Float(10, 384, 27, 27) = onnx::Concat[axis=1](%100, %102), scope: SqueezeNet/Sequential[features]/Fire[8]\n",
      "  %104 : Float(10, 48, 27, 27) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%103, %33, %34), scope: SqueezeNet/Sequential[features]/Fire[9]/Conv2d[squeeze]\n",
      "  %105 : Float(10, 48, 27, 27) = onnx::Relu(%104), scope: SqueezeNet/Sequential[features]/Fire[9]/ReLU[squeeze_activation]\n",
      "  %106 : Float(10, 192, 27, 27) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%105, %35, %36), scope: SqueezeNet/Sequential[features]/Fire[9]/Conv2d[expand1x1]\n",
      "  %107 : Float(10, 192, 27, 27) = onnx::Relu(%106), scope: SqueezeNet/Sequential[features]/Fire[9]/ReLU[expand1x1_activation]\n",
      "  %108 : Float(10, 192, 27, 27) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%105, %37, %38), scope: SqueezeNet/Sequential[features]/Fire[9]/Conv2d[expand3x3]\n",
      "  %109 : Float(10, 192, 27, 27) = onnx::Relu(%108), scope: SqueezeNet/Sequential[features]/Fire[9]/ReLU[expand3x3_activation]\n",
      "  %110 : Float(10, 384, 27, 27) = onnx::Concat[axis=1](%107, %109), scope: SqueezeNet/Sequential[features]/Fire[9]\n",
      "  %111 : Float(10, 64, 27, 27) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%110, %39, %40), scope: SqueezeNet/Sequential[features]/Fire[10]/Conv2d[squeeze]\n",
      "  %112 : Float(10, 64, 27, 27) = onnx::Relu(%111), scope: SqueezeNet/Sequential[features]/Fire[10]/ReLU[squeeze_activation]\n",
      "  %113 : Float(10, 256, 27, 27) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%112, %41, %42), scope: SqueezeNet/Sequential[features]/Fire[10]/Conv2d[expand1x1]\n",
      "  %114 : Float(10, 256, 27, 27) = onnx::Relu(%113), scope: SqueezeNet/Sequential[features]/Fire[10]/ReLU[expand1x1_activation]\n",
      "  %115 : Float(10, 256, 27, 27) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%112, %43, %44), scope: SqueezeNet/Sequential[features]/Fire[10]/Conv2d[expand3x3]\n",
      "  %116 : Float(10, 256, 27, 27) = onnx::Relu(%115), scope: SqueezeNet/Sequential[features]/Fire[10]/ReLU[expand3x3_activation]\n",
      "  %117 : Float(10, 512, 27, 27) = onnx::Concat[axis=1](%114, %116), scope: SqueezeNet/Sequential[features]/Fire[10]\n",
      "  %118 : int[] = onnx::Constant[value= 3  3 [ CPULongType{2} ]]()\n",
      "  %119 : int[] = onnx::Constant[value= 2  2 [ CPULongType{2} ]]()\n",
      "  %120 : int[] = onnx::Constant[value= 0  0 [ CPULongType{2} ]]()\n",
      "  %121 : int[] = onnx::Constant[value= 1  1 [ CPULongType{2} ]]()\n",
      "  %122 : Long() = onnx::Constant[value={1}]()\n",
      "  %123 : Float(10, 512, 13, 13), %124 : Long(10, 512, 13, 13) = aten::max_pool2d_with_indices(%117, %118, %119, %120, %121, %122), scope: SqueezeNet/Sequential[features]/MaxPool2d[11]\n",
      "  %125 : Float(10, 64, 13, 13) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%123, %45, %46), scope: SqueezeNet/Sequential[features]/Fire[12]/Conv2d[squeeze]\n",
      "  %126 : Float(10, 64, 13, 13) = onnx::Relu(%125), scope: SqueezeNet/Sequential[features]/Fire[12]/ReLU[squeeze_activation]\n",
      "  %127 : Float(10, 256, 13, 13) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%126, %47, %48), scope: SqueezeNet/Sequential[features]/Fire[12]/Conv2d[expand1x1]\n",
      "  %128 : Float(10, 256, 13, 13) = onnx::Relu(%127), scope: SqueezeNet/Sequential[features]/Fire[12]/ReLU[expand1x1_activation]\n",
      "  %129 : Float(10, 256, 13, 13) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%126, %49, %50), scope: SqueezeNet/Sequential[features]/Fire[12]/Conv2d[expand3x3]\n",
      "  %130 : Float(10, 256, 13, 13) = onnx::Relu(%129), scope: SqueezeNet/Sequential[features]/Fire[12]/ReLU[expand3x3_activation]\n",
      "  %131 : Float(10, 512, 13, 13) = onnx::Concat[axis=1](%128, %130), scope: SqueezeNet/Sequential[features]/Fire[12]\n",
      "  %132 : Float(10, 512, 13, 13), %133 : Dynamic = onnx::Dropout[ratio=0.5](%131), scope: SqueezeNet/Sequential[classifier]/Dropout[0]\n",
      "  %134 : Float(10, 1000, 13, 13) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%132, %51, %52), scope: SqueezeNet/Sequential[classifier]/Conv2d[1]\n",
      "  %135 : Float(10, 1000, 13, 13) = onnx::Relu(%134), scope: SqueezeNet/Sequential[classifier]/ReLU[2]\n",
      "  %136 : Dynamic = onnx::Pad[mode=\"constant\", pads=[0, 0, 0, 0, 0, 0, 0, 0], value=0](%135), scope: SqueezeNet/Sequential[classifier]/AvgPool2d[3]\n",
      "  %137 : Float(10, 1000, 1, 1) = onnx::AveragePool[kernel_shape=[13, 13], pads=[0, 0, 0, 0], strides=[1, 1]](%136), scope: SqueezeNet/Sequential[classifier]/AvgPool2d[3]\n",
      "  %138 : Long() = onnx::Constant[value={0}]()\n",
      "  %139 : Dynamic = onnx::Shape(%137), scope: SqueezeNet\n",
      "  %140 : Long() = onnx::Gather[axis=0](%139, %138), scope: SqueezeNet\n",
      "  %141 : Long() = onnx::Constant[value={1000}]()\n",
      "  %142 : Dynamic = onnx::Unsqueeze[axes=[0]](%140), scope: SqueezeNet\n",
      "  %143 : Dynamic = onnx::Unsqueeze[axes=[0]](%141), scope: SqueezeNet\n",
      "  %144 : int[] = onnx::Concat[axis=0](%142, %143), scope: SqueezeNet\n",
      "  %145 : Float(10, 1000) = onnx::Reshape(%137, %144), scope: SqueezeNet\n",
      "  return (%145);\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torch/onnx/symbolic.py:130: UserWarning: ONNX export failed on max_pool2d_with_indices because ceil_mode not supported\n",
      "  warnings.warn(\"ONNX export failed on \" + op + \" because \" + msg + \" not supported\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "ONNX export failed: Couldn't export operator aten::max_pool2d_with_indices\n\nDefined at:\n/usr/local/lib/python3.5/dist-packages/torch/nn/functional.py(409): max_pool2d\n/usr/local/lib/python3.5/dist-packages/torch/nn/modules/pooling.py(140): forward\n/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py(465): _slow_forward\n/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py(475): __call__\n/usr/local/lib/python3.5/dist-packages/torch/nn/modules/container.py(92): forward\n/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py(465): _slow_forward\n/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py(475): __call__\n/usr/local/lib/python3.5/dist-packages/torchvision/models/squeezenet.py(99): forward\n/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py(465): _slow_forward\n/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py(475): __call__\n/usr/local/lib/python3.5/dist-packages/torch/jit/__init__.py(146): forward\n/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py(477): __call__\n/usr/local/lib/python3.5/dist-packages/torch/jit/__init__.py(115): get_trace_graph\n/usr/local/lib/python3.5/dist-packages/torch/onnx/utils.py(191): _trace_and_get_graph_from_model\n/usr/local/lib/python3.5/dist-packages/torch/onnx/utils.py(223): _model_to_graph\n/usr/local/lib/python3.5/dist-packages/torch/onnx/utils.py(280): _export\n/usr/local/lib/python3.5/dist-packages/torch/onnx/utils.py(104): export\n/usr/local/lib/python3.5/dist-packages/torch/onnx/__init__.py(27): export\n<ipython-input-2-847ef1cbec43>(11): <module>\n/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py(3267): run_code\n/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py(3191): run_ast_nodes\n/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py(3020): run_cell_async\n/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py(67): _pseudo_sync_runner\n/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py(2845): _run_cell\n/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py(2819): run_cell\n/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py(536): run_cell\n/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py(294): do_execute\n/usr/local/lib/python3.5/dist-packages/tornado/gen.py(326): wrapper\n/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py(534): execute_request\n/usr/local/lib/python3.5/dist-packages/tornado/gen.py(326): wrapper\n/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py(267): dispatch_shell\n/usr/local/lib/python3.5/dist-packages/tornado/gen.py(326): wrapper\n/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py(357): process_one\n/usr/local/lib/python3.5/dist-packages/tornado/gen.py(1147): run\n/usr/local/lib/python3.5/dist-packages/tornado/gen.py(1080): __init__\n/usr/local/lib/python3.5/dist-packages/tornado/gen.py(346): wrapper\n/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py(370): dispatch_queue\n/usr/local/lib/python3.5/dist-packages/tornado/gen.py(1147): run\n/usr/local/lib/python3.5/dist-packages/tornado/gen.py(1233): inner\n/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py(300): null_wrapper\n/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py(758): _run_callback\n/usr/lib/python3.5/asyncio/events.py(125): _run\n/usr/lib/python3.5/asyncio/base_events.py(1312): _run_once\n/usr/lib/python3.5/asyncio/base_events.py(345): run_forever\n/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py(132): start\n/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py(505): start\n/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py(658): launch_instance\n/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py(16): <module>\n/usr/lib/python3.5/runpy.py(85): _run_code\n/usr/lib/python3.5/runpy.py(184): _run_module_as_main\n\n\nGraph we tried to export:\ngraph(%0 : Float(10, 3, 224, 224)\n      %1 : Float(96, 3, 7, 7)\n      %2 : Float(96)\n      %3 : Float(16, 96, 1, 1)\n      %4 : Float(16)\n      %5 : Float(64, 16, 1, 1)\n      %6 : Float(64)\n      %7 : Float(64, 16, 3, 3)\n      %8 : Float(64)\n      %9 : Float(16, 128, 1, 1)\n      %10 : Float(16)\n      %11 : Float(64, 16, 1, 1)\n      %12 : Float(64)\n      %13 : Float(64, 16, 3, 3)\n      %14 : Float(64)\n      %15 : Float(32, 128, 1, 1)\n      %16 : Float(32)\n      %17 : Float(128, 32, 1, 1)\n      %18 : Float(128)\n      %19 : Float(128, 32, 3, 3)\n      %20 : Float(128)\n      %21 : Float(32, 256, 1, 1)\n      %22 : Float(32)\n      %23 : Float(128, 32, 1, 1)\n      %24 : Float(128)\n      %25 : Float(128, 32, 3, 3)\n      %26 : Float(128)\n      %27 : Float(48, 256, 1, 1)\n      %28 : Float(48)\n      %29 : Float(192, 48, 1, 1)\n      %30 : Float(192)\n      %31 : Float(192, 48, 3, 3)\n      %32 : Float(192)\n      %33 : Float(48, 384, 1, 1)\n      %34 : Float(48)\n      %35 : Float(192, 48, 1, 1)\n      %36 : Float(192)\n      %37 : Float(192, 48, 3, 3)\n      %38 : Float(192)\n      %39 : Float(64, 384, 1, 1)\n      %40 : Float(64)\n      %41 : Float(256, 64, 1, 1)\n      %42 : Float(256)\n      %43 : Float(256, 64, 3, 3)\n      %44 : Float(256)\n      %45 : Float(64, 512, 1, 1)\n      %46 : Float(64)\n      %47 : Float(256, 64, 1, 1)\n      %48 : Float(256)\n      %49 : Float(256, 64, 3, 3)\n      %50 : Float(256)\n      %51 : Float(1000, 512, 1, 1)\n      %52 : Float(1000)) {\n  %53 : Float(10, 96, 109, 109) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 7], pads=[0, 0, 0, 0], strides=[2, 2]](%0, %1, %2), scope: SqueezeNet/Sequential[features]/Conv2d[0]\n  %54 : Float(10, 96, 109, 109) = onnx::Relu(%53), scope: SqueezeNet/Sequential[features]/ReLU[1]\n  %55 : int[] = onnx::Constant[value= 3  3 [ CPULongType{2} ]]()\n  %56 : int[] = onnx::Constant[value= 2  2 [ CPULongType{2} ]]()\n  %57 : int[] = onnx::Constant[value= 0  0 [ CPULongType{2} ]]()\n  %58 : int[] = onnx::Constant[value= 1  1 [ CPULongType{2} ]]()\n  %59 : Long() = onnx::Constant[value={1}]()\n  %60 : Float(10, 96, 54, 54), %61 : Long(10, 96, 54, 54) = aten::max_pool2d_with_indices(%54, %55, %56, %57, %58, %59), scope: SqueezeNet/Sequential[features]/MaxPool2d[2]\n  %62 : Float(10, 16, 54, 54) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%60, %3, %4), scope: SqueezeNet/Sequential[features]/Fire[3]/Conv2d[squeeze]\n  %63 : Float(10, 16, 54, 54) = onnx::Relu(%62), scope: SqueezeNet/Sequential[features]/Fire[3]/ReLU[squeeze_activation]\n  %64 : Float(10, 64, 54, 54) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%63, %5, %6), scope: SqueezeNet/Sequential[features]/Fire[3]/Conv2d[expand1x1]\n  %65 : Float(10, 64, 54, 54) = onnx::Relu(%64), scope: SqueezeNet/Sequential[features]/Fire[3]/ReLU[expand1x1_activation]\n  %66 : Float(10, 64, 54, 54) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%63, %7, %8), scope: SqueezeNet/Sequential[features]/Fire[3]/Conv2d[expand3x3]\n  %67 : Float(10, 64, 54, 54) = onnx::Relu(%66), scope: SqueezeNet/Sequential[features]/Fire[3]/ReLU[expand3x3_activation]\n  %68 : Float(10, 128, 54, 54) = onnx::Concat[axis=1](%65, %67), scope: SqueezeNet/Sequential[features]/Fire[3]\n  %69 : Float(10, 16, 54, 54) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%68, %9, %10), scope: SqueezeNet/Sequential[features]/Fire[4]/Conv2d[squeeze]\n  %70 : Float(10, 16, 54, 54) = onnx::Relu(%69), scope: SqueezeNet/Sequential[features]/Fire[4]/ReLU[squeeze_activation]\n  %71 : Float(10, 64, 54, 54) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%70, %11, %12), scope: SqueezeNet/Sequential[features]/Fire[4]/Conv2d[expand1x1]\n  %72 : Float(10, 64, 54, 54) = onnx::Relu(%71), scope: SqueezeNet/Sequential[features]/Fire[4]/ReLU[expand1x1_activation]\n  %73 : Float(10, 64, 54, 54) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%70, %13, %14), scope: SqueezeNet/Sequential[features]/Fire[4]/Conv2d[expand3x3]\n  %74 : Float(10, 64, 54, 54) = onnx::Relu(%73), scope: SqueezeNet/Sequential[features]/Fire[4]/ReLU[expand3x3_activation]\n  %75 : Float(10, 128, 54, 54) = onnx::Concat[axis=1](%72, %74), scope: SqueezeNet/Sequential[features]/Fire[4]\n  %76 : Float(10, 32, 54, 54) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%75, %15, %16), scope: SqueezeNet/Sequential[features]/Fire[5]/Conv2d[squeeze]\n  %77 : Float(10, 32, 54, 54) = onnx::Relu(%76), scope: SqueezeNet/Sequential[features]/Fire[5]/ReLU[squeeze_activation]\n  %78 : Float(10, 128, 54, 54) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%77, %17, %18), scope: SqueezeNet/Sequential[features]/Fire[5]/Conv2d[expand1x1]\n  %79 : Float(10, 128, 54, 54) = onnx::Relu(%78), scope: SqueezeNet/Sequential[features]/Fire[5]/ReLU[expand1x1_activation]\n  %80 : Float(10, 128, 54, 54) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%77, %19, %20), scope: SqueezeNet/Sequential[features]/Fire[5]/Conv2d[expand3x3]\n  %81 : Float(10, 128, 54, 54) = onnx::Relu(%80), scope: SqueezeNet/Sequential[features]/Fire[5]/ReLU[expand3x3_activation]\n  %82 : Float(10, 256, 54, 54) = onnx::Concat[axis=1](%79, %81), scope: SqueezeNet/Sequential[features]/Fire[5]\n  %83 : int[] = onnx::Constant[value= 3  3 [ CPULongType{2} ]]()\n  %84 : int[] = onnx::Constant[value= 2  2 [ CPULongType{2} ]]()\n  %85 : int[] = onnx::Constant[value= 0  0 [ CPULongType{2} ]]()\n  %86 : int[] = onnx::Constant[value= 1  1 [ CPULongType{2} ]]()\n  %87 : Long() = onnx::Constant[value={1}]()\n  %88 : Float(10, 256, 27, 27), %89 : Long(10, 256, 27, 27) = aten::max_pool2d_with_indices(%82, %83, %84, %85, %86, %87), scope: SqueezeNet/Sequential[features]/MaxPool2d[6]\n  %90 : Float(10, 32, 27, 27) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%88, %21, %22), scope: SqueezeNet/Sequential[features]/Fire[7]/Conv2d[squeeze]\n  %91 : Float(10, 32, 27, 27) = onnx::Relu(%90), scope: SqueezeNet/Sequential[features]/Fire[7]/ReLU[squeeze_activation]\n  %92 : Float(10, 128, 27, 27) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%91, %23, %24), scope: SqueezeNet/Sequential[features]/Fire[7]/Conv2d[expand1x1]\n  %93 : Float(10, 128, 27, 27) = onnx::Relu(%92), scope: SqueezeNet/Sequential[features]/Fire[7]/ReLU[expand1x1_activation]\n  %94 : Float(10, 128, 27, 27) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%91, %25, %26), scope: SqueezeNet/Sequential[features]/Fire[7]/Conv2d[expand3x3]\n  %95 : Float(10, 128, 27, 27) = onnx::Relu(%94), scope: SqueezeNet/Sequential[features]/Fire[7]/ReLU[expand3x3_activation]\n  %96 : Float(10, 256, 27, 27) = onnx::Concat[axis=1](%93, %95), scope: SqueezeNet/Sequential[features]/Fire[7]\n  %97 : Float(10, 48, 27, 27) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%96, %27, %28), scope: SqueezeNet/Sequential[features]/Fire[8]/Conv2d[squeeze]\n  %98 : Float(10, 48, 27, 27) = onnx::Relu(%97), scope: SqueezeNet/Sequential[features]/Fire[8]/ReLU[squeeze_activation]\n  %99 : Float(10, 192, 27, 27) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%98, %29, %30), scope: SqueezeNet/Sequential[features]/Fire[8]/Conv2d[expand1x1]\n  %100 : Float(10, 192, 27, 27) = onnx::Relu(%99), scope: SqueezeNet/Sequential[features]/Fire[8]/ReLU[expand1x1_activation]\n  %101 : Float(10, 192, 27, 27) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%98, %31, %32), scope: SqueezeNet/Sequential[features]/Fire[8]/Conv2d[expand3x3]\n  %102 : Float(10, 192, 27, 27) = onnx::Relu(%101), scope: SqueezeNet/Sequential[features]/Fire[8]/ReLU[expand3x3_activation]\n  %103 : Float(10, 384, 27, 27) = onnx::Concat[axis=1](%100, %102), scope: SqueezeNet/Sequential[features]/Fire[8]\n  %104 : Float(10, 48, 27, 27) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%103, %33, %34), scope: SqueezeNet/Sequential[features]/Fire[9]/Conv2d[squeeze]\n  %105 : Float(10, 48, 27, 27) = onnx::Relu(%104), scope: SqueezeNet/Sequential[features]/Fire[9]/ReLU[squeeze_activation]\n  %106 : Float(10, 192, 27, 27) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%105, %35, %36), scope: SqueezeNet/Sequential[features]/Fire[9]/Conv2d[expand1x1]\n  %107 : Float(10, 192, 27, 27) = onnx::Relu(%106), scope: SqueezeNet/Sequential[features]/Fire[9]/ReLU[expand1x1_activation]\n  %108 : Float(10, 192, 27, 27) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%105, %37, %38), scope: SqueezeNet/Sequential[features]/Fire[9]/Conv2d[expand3x3]\n  %109 : Float(10, 192, 27, 27) = onnx::Relu(%108), scope: SqueezeNet/Sequential[features]/Fire[9]/ReLU[expand3x3_activation]\n  %110 : Float(10, 384, 27, 27) = onnx::Concat[axis=1](%107, %109), scope: SqueezeNet/Sequential[features]/Fire[9]\n  %111 : Float(10, 64, 27, 27) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%110, %39, %40), scope: SqueezeNet/Sequential[features]/Fire[10]/Conv2d[squeeze]\n  %112 : Float(10, 64, 27, 27) = onnx::Relu(%111), scope: SqueezeNet/Sequential[features]/Fire[10]/ReLU[squeeze_activation]\n  %113 : Float(10, 256, 27, 27) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%112, %41, %42), scope: SqueezeNet/Sequential[features]/Fire[10]/Conv2d[expand1x1]\n  %114 : Float(10, 256, 27, 27) = onnx::Relu(%113), scope: SqueezeNet/Sequential[features]/Fire[10]/ReLU[expand1x1_activation]\n  %115 : Float(10, 256, 27, 27) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%112, %43, %44), scope: SqueezeNet/Sequential[features]/Fire[10]/Conv2d[expand3x3]\n  %116 : Float(10, 256, 27, 27) = onnx::Relu(%115), scope: SqueezeNet/Sequential[features]/Fire[10]/ReLU[expand3x3_activation]\n  %117 : Float(10, 512, 27, 27) = onnx::Concat[axis=1](%114, %116), scope: SqueezeNet/Sequential[features]/Fire[10]\n  %118 : int[] = onnx::Constant[value= 3  3 [ CPULongType{2} ]]()\n  %119 : int[] = onnx::Constant[value= 2  2 [ CPULongType{2} ]]()\n  %120 : int[] = onnx::Constant[value= 0  0 [ CPULongType{2} ]]()\n  %121 : int[] = onnx::Constant[value= 1  1 [ CPULongType{2} ]]()\n  %122 : Long() = onnx::Constant[value={1}]()\n  %123 : Float(10, 512, 13, 13), %124 : Long(10, 512, 13, 13) = aten::max_pool2d_with_indices(%117, %118, %119, %120, %121, %122), scope: SqueezeNet/Sequential[features]/MaxPool2d[11]\n  %125 : Float(10, 64, 13, 13) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%123, %45, %46), scope: SqueezeNet/Sequential[features]/Fire[12]/Conv2d[squeeze]\n  %126 : Float(10, 64, 13, 13) = onnx::Relu(%125), scope: SqueezeNet/Sequential[features]/Fire[12]/ReLU[squeeze_activation]\n  %127 : Float(10, 256, 13, 13) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%126, %47, %48), scope: SqueezeNet/Sequential[features]/Fire[12]/Conv2d[expand1x1]\n  %128 : Float(10, 256, 13, 13) = onnx::Relu(%127), scope: SqueezeNet/Sequential[features]/Fire[12]/ReLU[expand1x1_activation]\n  %129 : Float(10, 256, 13, 13) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%126, %49, %50), scope: SqueezeNet/Sequential[features]/Fire[12]/Conv2d[expand3x3]\n  %130 : Float(10, 256, 13, 13) = onnx::Relu(%129), scope: SqueezeNet/Sequential[features]/Fire[12]/ReLU[expand3x3_activation]\n  %131 : Float(10, 512, 13, 13) = onnx::Concat[axis=1](%128, %130), scope: SqueezeNet/Sequential[features]/Fire[12]\n  %132 : Float(10, 512, 13, 13), %133 : Dynamic = onnx::Dropout[ratio=0.5](%131), scope: SqueezeNet/Sequential[classifier]/Dropout[0]\n  %134 : Float(10, 1000, 13, 13) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%132, %51, %52), scope: SqueezeNet/Sequential[classifier]/Conv2d[1]\n  %135 : Float(10, 1000, 13, 13) = onnx::Relu(%134), scope: SqueezeNet/Sequential[classifier]/ReLU[2]\n  %136 : Dynamic = onnx::Pad[mode=\"constant\", pads=[0, 0, 0, 0, 0, 0, 0, 0], value=0](%135), scope: SqueezeNet/Sequential[classifier]/AvgPool2d[3]\n  %137 : Float(10, 1000, 1, 1) = onnx::AveragePool[kernel_shape=[13, 13], pads=[0, 0, 0, 0], strides=[1, 1]](%136), scope: SqueezeNet/Sequential[classifier]/AvgPool2d[3]\n  %138 : Long() = onnx::Constant[value={0}]()\n  %139 : Dynamic = onnx::Shape(%137), scope: SqueezeNet\n  %140 : Long() = onnx::Gather[axis=0](%139, %138), scope: SqueezeNet\n  %141 : Long() = onnx::Constant[value={1000}]()\n  %142 : Dynamic = onnx::Unsqueeze[axes=[0]](%140), scope: SqueezeNet\n  %143 : Dynamic = onnx::Unsqueeze[axes=[0]](%141), scope: SqueezeNet\n  %144 : int[] = onnx::Concat[axis=0](%142, %143), scope: SqueezeNet\n  %145 : Float(10, 1000) = onnx::Reshape(%137, %144), scope: SqueezeNet\n  return (%145);\n}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-847ef1cbec43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m                   \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                   \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                   \u001b[0mexport_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                  )\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/onnx/__init__.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, aten, export_raw_ir, operator_export_type)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0moperator_export_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOperatorExportTypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mONNX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     _export(model, args, f, export_params, verbose, training, input_names, output_names,\n\u001b[0;32m--> 104\u001b[0;31m             operator_export_type=operator_export_type)\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, example_outputs, propagate)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0mdefer_weight_export\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexport_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mExportTypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPROTOBUF_FILE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexport_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexport_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_onnx_opset_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefer_weight_export\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator_export_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexport_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_onnx_opset_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator_export_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: ONNX export failed: Couldn't export operator aten::max_pool2d_with_indices\n\nDefined at:\n/usr/local/lib/python3.5/dist-packages/torch/nn/functional.py(409): max_pool2d\n/usr/local/lib/python3.5/dist-packages/torch/nn/modules/pooling.py(140): forward\n/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py(465): _slow_forward\n/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py(475): __call__\n/usr/local/lib/python3.5/dist-packages/torch/nn/modules/container.py(92): forward\n/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py(465): _slow_forward\n/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py(475): __call__\n/usr/local/lib/python3.5/dist-packages/torchvision/models/squeezenet.py(99): forward\n/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py(465): _slow_forward\n/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py(475): __call__\n/usr/local/lib/python3.5/dist-packages/torch/jit/__init__.py(146): forward\n/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py(477): __call__\n/usr/local/lib/python3.5/dist-packages/torch/jit/__init__.py(115): get_trace_graph\n/usr/local/lib/python3.5/dist-packages/torch/onnx/utils.py(191): _trace_and_get_graph_from_model\n/usr/local/lib/python3.5/dist-packages/torch/onnx/utils.py(223): _model_to_graph\n/usr/local/lib/python3.5/dist-packages/torch/onnx/utils.py(280): _export\n/usr/local/lib/python3.5/dist-packages/torch/onnx/utils.py(104): export\n/usr/local/lib/python3.5/dist-packages/torch/onnx/__init__.py(27): export\n<ipython-input-2-847ef1cbec43>(11): <module>\n/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py(3267): run_code\n/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py(3191): run_ast_nodes\n/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py(3020): run_cell_async\n/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py(67): _pseudo_sync_runner\n/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py(2845): _run_cell\n/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py(2819): run_cell\n/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py(536): run_cell\n/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py(294): do_execute\n/usr/local/lib/python3.5/dist-packages/tornado/gen.py(326): wrapper\n/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py(534): execute_request\n/usr/local/lib/python3.5/dist-packages/tornado/gen.py(326): wrapper\n/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py(267): dispatch_shell\n/usr/local/lib/python3.5/dist-packages/tornado/gen.py(326): wrapper\n/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py(357): process_one\n/usr/local/lib/python3.5/dist-packages/tornado/gen.py(1147): run\n/usr/local/lib/python3.5/dist-packages/tornado/gen.py(1080): __init__\n/usr/local/lib/python3.5/dist-packages/tornado/gen.py(346): wrapper\n/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py(370): dispatch_queue\n/usr/local/lib/python3.5/dist-packages/tornado/gen.py(1147): run\n/usr/local/lib/python3.5/dist-packages/tornado/gen.py(1233): inner\n/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py(300): null_wrapper\n/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py(758): _run_callback\n/usr/lib/python3.5/asyncio/events.py(125): _run\n/usr/lib/python3.5/asyncio/base_events.py(1312): _run_once\n/usr/lib/python3.5/asyncio/base_events.py(345): run_forever\n/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py(132): start\n/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py(505): start\n/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py(658): launch_instance\n/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py(16): <module>\n/usr/lib/python3.5/runpy.py(85): _run_code\n/usr/lib/python3.5/runpy.py(184): _run_module_as_main\n\n\nGraph we tried to export:\ngraph(%0 : Float(10, 3, 224, 224)\n      %1 : Float(96, 3, 7, 7)\n      %2 : Float(96)\n      %3 : Float(16, 96, 1, 1)\n      %4 : Float(16)\n      %5 : Float(64, 16, 1, 1)\n      %6 : Float(64)\n      %7 : Float(64, 16, 3, 3)\n      %8 : Float(64)\n      %9 : Float(16, 128, 1, 1)\n      %10 : Float(16)\n      %11 : Float(64, 16, 1, 1)\n      %12 : Float(64)\n      %13 : Float(64, 16, 3, 3)\n      %14 : Float(64)\n      %15 : Float(32, 128, 1, 1)\n      %16 : Float(32)\n      %17 : Float(128, 32, 1, 1)\n      %18 : Float(128)\n      %19 : Float(128, 32, 3, 3)\n      %20 : Float(128)\n      %21 : Float(32, 256, 1, 1)\n      %22 : Float(32)\n      %23 : Float(128, 32, 1, 1)\n      %24 : Float(128)\n      %25 : Float(128, 32, 3, 3)\n      %26 : Float(128)\n      %27 : Float(48, 256, 1, 1)\n      %28 : Float(48)\n      %29 : Float(192, 48, 1, 1)\n      %30 : Float(192)\n      %31 : Float(192, 48, 3, 3)\n      %32 : Float(192)\n      %33 : Float(48, 384, 1, 1)\n      %34 : Float(48)\n      %35 : Float(192, 48, 1, 1)\n      %36 : Float(192)\n      %37 : Float(192, 48, 3, 3)\n      %38 : Float(192)\n      %39 : Float(64, 384, 1, 1)\n      %40 : Float(64)\n      %41 : Float(256, 64, 1, 1)\n      %42 : Float(256)\n      %43 : Float(256, 64, 3, 3)\n      %44 : Float(256)\n      %45 : Float(64, 512, 1, 1)\n      %46 : Float(64)\n      %47 : Float(256, 64, 1, 1)\n      %48 : Float(256)\n      %49 : Float(256, 64, 3, 3)\n      %50 : Float(256)\n      %51 : Float(1000, 512, 1, 1)\n      %52 : Float(1000)) {\n  %53 : Float(10, 96, 109, 109) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 7], pads=[0, 0, 0, 0], strides=[2, 2]](%0, %1, %2), scope: SqueezeNet/Sequential[features]/Conv2d[0]\n  %54 : Float(10, 96, 109, 109) = onnx::Relu(%53), scope: SqueezeNet/Sequential[features]/ReLU[1]\n  %55 : int[] = onnx::Constant[value= 3  3 [ CPULongType{2} ]]()\n  %56 : int[] = onnx::Constant[value= 2  2 [ CPULongType{2} ]]()\n  %57 : int[] = onnx::Constant[value= 0  0 [ CPULongType{2} ]]()\n  %58 : int[] = onnx::Constant[value= 1  1 [ CPULongType{2} ]]()\n  %59 : Long() = onnx::Constant[value={1}]()\n  %60 : Float(10, 96, 54, 54), %61 : Long(10, 96, 54, 54) = aten::max_pool2d_with_indices(%54, %55, %56, %57, %58, %59), scope: SqueezeNet/Sequential[features]/MaxPool2d[2]\n  %62 : Float(10, 16, 54, 54) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%60, %3, %4), scope: SqueezeNet/Sequential[features]/Fire[3]/Conv2d[squeeze]\n  %63 : Float(10, 16, 54, 54) = onnx::Relu(%62), scope: SqueezeNet/Sequential[features]/Fire[3]/ReLU[squeeze_activation]\n  %64 : Float(10, 64, 54, 54) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%63, %5, %6), scope: SqueezeNet/Sequential[features]/Fire[3]/Conv2d[expand1x1]\n  %65 : Float(10, 64, 54, 54) = onnx::Relu(%64), scope: SqueezeNet/Sequential[features]/Fire[3]/ReLU[expand1x1_activation]\n  %66 : Float(10, 64, 54, 54) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%63, %7, %8), scope: SqueezeNet/Sequential[features]/Fire[3]/Conv2d[expand3x3]\n  %67 : Float(10, 64, 54, 54) = onnx::Relu(%66), scope: SqueezeNet/Sequential[features]/Fire[3]/ReLU[expand3x3_activation]\n  %68 : Float(10, 128, 54, 54) = onnx::Concat[axis=1](%65, %67), scope: SqueezeNet/Sequential[features]/Fire[3]\n  %69 : Float(10, 16, 54, 54) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%68, %9, %10), scope: SqueezeNet/Sequential[features]/Fire[4]/Conv2d[squeeze]\n  %70 : Float(10, 16, 54, 54) = onnx::Relu(%69), scope: SqueezeNet/Sequential[features]/Fire[4]/ReLU[squeeze_activation]\n  %71 : Float(10, 64, 54, 54) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%70, %11, %12), scope: SqueezeNet/Sequential[features]/Fire[4]/Conv2d[expand1x1]\n  %72 : Float(10, 64, 54, 54) = onnx::Relu(%71), scope: SqueezeNet/Sequential[features]/Fire[4]/ReLU[expand1x1_activation]\n  %73 : Float(10, 64, 54, 54) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%70, %13, %14), scope: SqueezeNet/Sequential[features]/Fire[4]/Conv2d[expand3x3]\n  %74 : Float(10, 64, 54, 54) = onnx::Relu(%73), scope: SqueezeNet/Sequential[features]/Fire[4]/ReLU[expand3x3_activation]\n  %75 : Float(10, 128, 54, 54) = onnx::Concat[axis=1](%72, %74), scope: SqueezeNet/Sequential[features]/Fire[4]\n  %76 : Float(10, 32, 54, 54) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%75, %15, %16), scope: SqueezeNet/Sequential[features]/Fire[5]/Conv2d[squeeze]\n  %77 : Float(10, 32, 54, 54) = onnx::Relu(%76), scope: SqueezeNet/Sequential[features]/Fire[5]/ReLU[squeeze_activation]\n  %78 : Float(10, 128, 54, 54) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%77, %17, %18), scope: SqueezeNet/Sequential[features]/Fire[5]/Conv2d[expand1x1]\n  %79 : Float(10, 128, 54, 54) = onnx::Relu(%78), scope: SqueezeNet/Sequential[features]/Fire[5]/ReLU[expand1x1_activation]\n  %80 : Float(10, 128, 54, 54) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%77, %19, %20), scope: SqueezeNet/Sequential[features]/Fire[5]/Conv2d[expand3x3]\n  %81 : Float(10, 128, 54, 54) = onnx::Relu(%80), scope: SqueezeNet/Sequential[features]/Fire[5]/ReLU[expand3x3_activation]\n  %82 : Float(10, 256, 54, 54) = onnx::Concat[axis=1](%79, %81), scope: SqueezeNet/Sequential[features]/Fire[5]\n  %83 : int[] = onnx::Constant[value= 3  3 [ CPULongType{2} ]]()\n  %84 : int[] = onnx::Constant[value= 2  2 [ CPULongType{2} ]]()\n  %85 : int[] = onnx::Constant[value= 0  0 [ CPULongType{2} ]]()\n  %86 : int[] = onnx::Constant[value= 1  1 [ CPULongType{2} ]]()\n  %87 : Long() = onnx::Constant[value={1}]()\n  %88 : Float(10, 256, 27, 27), %89 : Long(10, 256, 27, 27) = aten::max_pool2d_with_indices(%82, %83, %84, %85, %86, %87), scope: SqueezeNet/Sequential[features]/MaxPool2d[6]\n  %90 : Float(10, 32, 27, 27) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%88, %21, %22), scope: SqueezeNet/Sequential[features]/Fire[7]/Conv2d[squeeze]\n  %91 : Float(10, 32, 27, 27) = onnx::Relu(%90), scope: SqueezeNet/Sequential[features]/Fire[7]/ReLU[squeeze_activation]\n  %92 : Float(10, 128, 27, 27) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%91, %23, %24), scope: SqueezeNet/Sequential[features]/Fire[7]/Conv2d[expand1x1]\n  %93 : Float(10, 128, 27, 27) = onnx::Relu(%92), scope: SqueezeNet/Sequential[features]/Fire[7]/ReLU[expand1x1_activation]\n  %94 : Float(10, 128, 27, 27) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%91, %25, %26), scope: SqueezeNet/Sequential[features]/Fire[7]/Conv2d[expand3x3]\n  %95 : Float(10, 128, 27, 27) = onnx::Relu(%94), scope: SqueezeNet/Sequential[features]/Fire[7]/ReLU[expand3x3_activation]\n  %96 : Float(10, 256, 27, 27) = onnx::Concat[axis=1](%93, %95), scope: SqueezeNet/Sequential[features]/Fire[7]\n  %97 : Float(10, 48, 27, 27) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%96, %27, %28), scope: SqueezeNet/Sequential[features]/Fire[8]/Conv2d[squeeze]\n  %98 : Float(10, 48, 27, 27) = onnx::Relu(%97), scope: SqueezeNet/Sequential[features]/Fire[8]/ReLU[squeeze_activation]\n  %99 : Float(10, 192, 27, 27) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%98, %29, %30), scope: SqueezeNet/Sequential[features]/Fire[8]/Conv2d[expand1x1]\n  %100 : Float(10, 192, 27, 27) = onnx::Relu(%99), scope: SqueezeNet/Sequential[features]/Fire[8]/ReLU[expand1x1_activation]\n  %101 : Float(10, 192, 27, 27) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%98, %31, %32), scope: SqueezeNet/Sequential[features]/Fire[8]/Conv2d[expand3x3]\n  %102 : Float(10, 192, 27, 27) = onnx::Relu(%101), scope: SqueezeNet/Sequential[features]/Fire[8]/ReLU[expand3x3_activation]\n  %103 : Float(10, 384, 27, 27) = onnx::Concat[axis=1](%100, %102), scope: SqueezeNet/Sequential[features]/Fire[8]\n  %104 : Float(10, 48, 27, 27) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%103, %33, %34), scope: SqueezeNet/Sequential[features]/Fire[9]/Conv2d[squeeze]\n  %105 : Float(10, 48, 27, 27) = onnx::Relu(%104), scope: SqueezeNet/Sequential[features]/Fire[9]/ReLU[squeeze_activation]\n  %106 : Float(10, 192, 27, 27) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%105, %35, %36), scope: SqueezeNet/Sequential[features]/Fire[9]/Conv2d[expand1x1]\n  %107 : Float(10, 192, 27, 27) = onnx::Relu(%106), scope: SqueezeNet/Sequential[features]/Fire[9]/ReLU[expand1x1_activation]\n  %108 : Float(10, 192, 27, 27) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%105, %37, %38), scope: SqueezeNet/Sequential[features]/Fire[9]/Conv2d[expand3x3]\n  %109 : Float(10, 192, 27, 27) = onnx::Relu(%108), scope: SqueezeNet/Sequential[features]/Fire[9]/ReLU[expand3x3_activation]\n  %110 : Float(10, 384, 27, 27) = onnx::Concat[axis=1](%107, %109), scope: SqueezeNet/Sequential[features]/Fire[9]\n  %111 : Float(10, 64, 27, 27) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%110, %39, %40), scope: SqueezeNet/Sequential[features]/Fire[10]/Conv2d[squeeze]\n  %112 : Float(10, 64, 27, 27) = onnx::Relu(%111), scope: SqueezeNet/Sequential[features]/Fire[10]/ReLU[squeeze_activation]\n  %113 : Float(10, 256, 27, 27) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%112, %41, %42), scope: SqueezeNet/Sequential[features]/Fire[10]/Conv2d[expand1x1]\n  %114 : Float(10, 256, 27, 27) = onnx::Relu(%113), scope: SqueezeNet/Sequential[features]/Fire[10]/ReLU[expand1x1_activation]\n  %115 : Float(10, 256, 27, 27) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%112, %43, %44), scope: SqueezeNet/Sequential[features]/Fire[10]/Conv2d[expand3x3]\n  %116 : Float(10, 256, 27, 27) = onnx::Relu(%115), scope: SqueezeNet/Sequential[features]/Fire[10]/ReLU[expand3x3_activation]\n  %117 : Float(10, 512, 27, 27) = onnx::Concat[axis=1](%114, %116), scope: SqueezeNet/Sequential[features]/Fire[10]\n  %118 : int[] = onnx::Constant[value= 3  3 [ CPULongType{2} ]]()\n  %119 : int[] = onnx::Constant[value= 2  2 [ CPULongType{2} ]]()\n  %120 : int[] = onnx::Constant[value= 0  0 [ CPULongType{2} ]]()\n  %121 : int[] = onnx::Constant[value= 1  1 [ CPULongType{2} ]]()\n  %122 : Long() = onnx::Constant[value={1}]()\n  %123 : Float(10, 512, 13, 13), %124 : Long(10, 512, 13, 13) = aten::max_pool2d_with_indices(%117, %118, %119, %120, %121, %122), scope: SqueezeNet/Sequential[features]/MaxPool2d[11]\n  %125 : Float(10, 64, 13, 13) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%123, %45, %46), scope: SqueezeNet/Sequential[features]/Fire[12]/Conv2d[squeeze]\n  %126 : Float(10, 64, 13, 13) = onnx::Relu(%125), scope: SqueezeNet/Sequential[features]/Fire[12]/ReLU[squeeze_activation]\n  %127 : Float(10, 256, 13, 13) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%126, %47, %48), scope: SqueezeNet/Sequential[features]/Fire[12]/Conv2d[expand1x1]\n  %128 : Float(10, 256, 13, 13) = onnx::Relu(%127), scope: SqueezeNet/Sequential[features]/Fire[12]/ReLU[expand1x1_activation]\n  %129 : Float(10, 256, 13, 13) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%126, %49, %50), scope: SqueezeNet/Sequential[features]/Fire[12]/Conv2d[expand3x3]\n  %130 : Float(10, 256, 13, 13) = onnx::Relu(%129), scope: SqueezeNet/Sequential[features]/Fire[12]/ReLU[expand3x3_activation]\n  %131 : Float(10, 512, 13, 13) = onnx::Concat[axis=1](%128, %130), scope: SqueezeNet/Sequential[features]/Fire[12]\n  %132 : Float(10, 512, 13, 13), %133 : Dynamic = onnx::Dropout[ratio=0.5](%131), scope: SqueezeNet/Sequential[classifier]/Dropout[0]\n  %134 : Float(10, 1000, 13, 13) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%132, %51, %52), scope: SqueezeNet/Sequential[classifier]/Conv2d[1]\n  %135 : Float(10, 1000, 13, 13) = onnx::Relu(%134), scope: SqueezeNet/Sequential[classifier]/ReLU[2]\n  %136 : Dynamic = onnx::Pad[mode=\"constant\", pads=[0, 0, 0, 0, 0, 0, 0, 0], value=0](%135), scope: SqueezeNet/Sequential[classifier]/AvgPool2d[3]\n  %137 : Float(10, 1000, 1, 1) = onnx::AveragePool[kernel_shape=[13, 13], pads=[0, 0, 0, 0], strides=[1, 1]](%136), scope: SqueezeNet/Sequential[classifier]/AvgPool2d[3]\n  %138 : Long() = onnx::Constant[value={0}]()\n  %139 : Dynamic = onnx::Shape(%137), scope: SqueezeNet\n  %140 : Long() = onnx::Gather[axis=0](%139, %138), scope: SqueezeNet\n  %141 : Long() = onnx::Constant[value={1000}]()\n  %142 : Dynamic = onnx::Unsqueeze[axes=[0]](%140), scope: SqueezeNet\n  %143 : Dynamic = onnx::Unsqueeze[axes=[0]](%141), scope: SqueezeNet\n  %144 : int[] = onnx::Concat[axis=0](%142, %143), scope: SqueezeNet\n  %145 : Float(10, 1000) = onnx::Reshape(%137, %144), scope: SqueezeNet\n  return (%145);\n}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if not os.path.isdir(\"model\"):\n",
    "    os.mkdir(\"model\")\n",
    "\n",
    "model_name = \"pytorch_squeezenet.onnx\"\n",
    "model_path = os.path.join(\"model\", model_name)\n",
    "torch.onnx.export(net, \n",
    "                  dummy_input, \n",
    "                  model_path, \n",
    "                  verbose=True,\n",
    "                  export_params=True\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the ONNX model to Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "\n",
    "# Load the ONNX file\n",
    "model = onnx.load(\"model/pytorch_squeezenet.onnx\")\n",
    "\n",
    "# Import the ONNX model to Tensorflow\n",
    "tf_rep = prepare(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "tf_out = tf_rep.run(dummy_input.numpy())\n",
    "torch_out = net(dummy_input).detach().numpy()\n",
    "\n",
    "np.testing.assert_almost_equal(tf_out[0], \n",
    "                               torch_out, \n",
    "                               decimal=3\n",
    "                              )\n",
    "\n",
    "print(\"Exported model has been executed on TF backend, and the result looks good!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
