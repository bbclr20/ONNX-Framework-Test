{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch-Resnet-ONNX-Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use PyTorch pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import os\n",
    "\n",
    "# Use an existing model from Torchvision, note it \n",
    "# will download this if not already on your computer (might take time)\n",
    "net = models.resnet18(pretrained=True)\n",
    "net.eval()\n",
    "\n",
    "# Create some sample input in the shape this model expects\n",
    "dummy_input = torch.ones(10, 3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%0 : Float(10, 3, 224, 224)\n",
      "      %1 : Float(64, 3, 7, 7)\n",
      "      %2 : Float(64)\n",
      "      %3 : Float(64)\n",
      "      %4 : Float(64)\n",
      "      %5 : Float(64)\n",
      "      %6 : Long()\n",
      "      %7 : Float(64, 64, 3, 3)\n",
      "      %8 : Float(64)\n",
      "      %9 : Float(64)\n",
      "      %10 : Float(64)\n",
      "      %11 : Float(64)\n",
      "      %12 : Long()\n",
      "      %13 : Float(64, 64, 3, 3)\n",
      "      %14 : Float(64)\n",
      "      %15 : Float(64)\n",
      "      %16 : Float(64)\n",
      "      %17 : Float(64)\n",
      "      %18 : Long()\n",
      "      %19 : Float(64, 64, 3, 3)\n",
      "      %20 : Float(64)\n",
      "      %21 : Float(64)\n",
      "      %22 : Float(64)\n",
      "      %23 : Float(64)\n",
      "      %24 : Long()\n",
      "      %25 : Float(64, 64, 3, 3)\n",
      "      %26 : Float(64)\n",
      "      %27 : Float(64)\n",
      "      %28 : Float(64)\n",
      "      %29 : Float(64)\n",
      "      %30 : Long()\n",
      "      %31 : Float(128, 64, 3, 3)\n",
      "      %32 : Float(128)\n",
      "      %33 : Float(128)\n",
      "      %34 : Float(128)\n",
      "      %35 : Float(128)\n",
      "      %36 : Long()\n",
      "      %37 : Float(128, 128, 3, 3)\n",
      "      %38 : Float(128)\n",
      "      %39 : Float(128)\n",
      "      %40 : Float(128)\n",
      "      %41 : Float(128)\n",
      "      %42 : Long()\n",
      "      %43 : Float(128, 64, 1, 1)\n",
      "      %44 : Float(128)\n",
      "      %45 : Float(128)\n",
      "      %46 : Float(128)\n",
      "      %47 : Float(128)\n",
      "      %48 : Long()\n",
      "      %49 : Float(128, 128, 3, 3)\n",
      "      %50 : Float(128)\n",
      "      %51 : Float(128)\n",
      "      %52 : Float(128)\n",
      "      %53 : Float(128)\n",
      "      %54 : Long()\n",
      "      %55 : Float(128, 128, 3, 3)\n",
      "      %56 : Float(128)\n",
      "      %57 : Float(128)\n",
      "      %58 : Float(128)\n",
      "      %59 : Float(128)\n",
      "      %60 : Long()\n",
      "      %61 : Float(256, 128, 3, 3)\n",
      "      %62 : Float(256)\n",
      "      %63 : Float(256)\n",
      "      %64 : Float(256)\n",
      "      %65 : Float(256)\n",
      "      %66 : Long()\n",
      "      %67 : Float(256, 256, 3, 3)\n",
      "      %68 : Float(256)\n",
      "      %69 : Float(256)\n",
      "      %70 : Float(256)\n",
      "      %71 : Float(256)\n",
      "      %72 : Long()\n",
      "      %73 : Float(256, 128, 1, 1)\n",
      "      %74 : Float(256)\n",
      "      %75 : Float(256)\n",
      "      %76 : Float(256)\n",
      "      %77 : Float(256)\n",
      "      %78 : Long()\n",
      "      %79 : Float(256, 256, 3, 3)\n",
      "      %80 : Float(256)\n",
      "      %81 : Float(256)\n",
      "      %82 : Float(256)\n",
      "      %83 : Float(256)\n",
      "      %84 : Long()\n",
      "      %85 : Float(256, 256, 3, 3)\n",
      "      %86 : Float(256)\n",
      "      %87 : Float(256)\n",
      "      %88 : Float(256)\n",
      "      %89 : Float(256)\n",
      "      %90 : Long()\n",
      "      %91 : Float(512, 256, 3, 3)\n",
      "      %92 : Float(512)\n",
      "      %93 : Float(512)\n",
      "      %94 : Float(512)\n",
      "      %95 : Float(512)\n",
      "      %96 : Long()\n",
      "      %97 : Float(512, 512, 3, 3)\n",
      "      %98 : Float(512)\n",
      "      %99 : Float(512)\n",
      "      %100 : Float(512)\n",
      "      %101 : Float(512)\n",
      "      %102 : Long()\n",
      "      %103 : Float(512, 256, 1, 1)\n",
      "      %104 : Float(512)\n",
      "      %105 : Float(512)\n",
      "      %106 : Float(512)\n",
      "      %107 : Float(512)\n",
      "      %108 : Long()\n",
      "      %109 : Float(512, 512, 3, 3)\n",
      "      %110 : Float(512)\n",
      "      %111 : Float(512)\n",
      "      %112 : Float(512)\n",
      "      %113 : Float(512)\n",
      "      %114 : Long()\n",
      "      %115 : Float(512, 512, 3, 3)\n",
      "      %116 : Float(512)\n",
      "      %117 : Float(512)\n",
      "      %118 : Float(512)\n",
      "      %119 : Float(512)\n",
      "      %120 : Long()\n",
      "      %121 : Float(1000, 512)\n",
      "      %122 : Float(1000)) {\n",
      "  %123 : Float(10, 64, 112, 112) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 7], pads=[3, 3, 3, 3], strides=[2, 2]](%0, %1), scope: ResNet/Conv2d[conv1]\n",
      "  %124 : Float(10, 64, 112, 112) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%123, %2, %3, %4, %5), scope: ResNet/BatchNorm2d[bn1]\n",
      "  %125 : Float(10, 64, 112, 112) = onnx::Relu(%124), scope: ResNet/ReLU[relu]\n",
      "  %126 : Float(10, 64, 56, 56) = onnx::MaxPool[kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%125), scope: ResNet/MaxPool2d[maxpool]\n",
      "  %127 : Float(10, 64, 56, 56) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%126, %7), scope: ResNet/Sequential[layer1]/BasicBlock[0]/Conv2d[conv1]\n",
      "  %128 : Float(10, 64, 56, 56) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%127, %8, %9, %10, %11), scope: ResNet/Sequential[layer1]/BasicBlock[0]/BatchNorm2d[bn1]\n",
      "  %129 : Float(10, 64, 56, 56) = onnx::Relu(%128), scope: ResNet/Sequential[layer1]/BasicBlock[0]/ReLU[relu]\n",
      "  %130 : Float(10, 64, 56, 56) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%129, %13), scope: ResNet/Sequential[layer1]/BasicBlock[0]/Conv2d[conv2]\n",
      "  %131 : Float(10, 64, 56, 56) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%130, %14, %15, %16, %17), scope: ResNet/Sequential[layer1]/BasicBlock[0]/BatchNorm2d[bn2]\n",
      "  %132 : Float(10, 64, 56, 56) = onnx::Add(%131, %126), scope: ResNet/Sequential[layer1]/BasicBlock[0]\n",
      "  %133 : Float(10, 64, 56, 56) = onnx::Relu(%132), scope: ResNet/Sequential[layer1]/BasicBlock[0]/ReLU[relu]\n",
      "  %134 : Float(10, 64, 56, 56) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%133, %19), scope: ResNet/Sequential[layer1]/BasicBlock[1]/Conv2d[conv1]\n",
      "  %135 : Float(10, 64, 56, 56) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%134, %20, %21, %22, %23), scope: ResNet/Sequential[layer1]/BasicBlock[1]/BatchNorm2d[bn1]\n",
      "  %136 : Float(10, 64, 56, 56) = onnx::Relu(%135), scope: ResNet/Sequential[layer1]/BasicBlock[1]/ReLU[relu]\n",
      "  %137 : Float(10, 64, 56, 56) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%136, %25), scope: ResNet/Sequential[layer1]/BasicBlock[1]/Conv2d[conv2]\n",
      "  %138 : Float(10, 64, 56, 56) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%137, %26, %27, %28, %29), scope: ResNet/Sequential[layer1]/BasicBlock[1]/BatchNorm2d[bn2]\n",
      "  %139 : Float(10, 64, 56, 56) = onnx::Add(%138, %133), scope: ResNet/Sequential[layer1]/BasicBlock[1]\n",
      "  %140 : Float(10, 64, 56, 56) = onnx::Relu(%139), scope: ResNet/Sequential[layer1]/BasicBlock[1]/ReLU[relu]\n",
      "  %141 : Float(10, 128, 28, 28) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%140, %31), scope: ResNet/Sequential[layer2]/BasicBlock[0]/Conv2d[conv1]\n",
      "  %142 : Float(10, 128, 28, 28) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%141, %32, %33, %34, %35), scope: ResNet/Sequential[layer2]/BasicBlock[0]/BatchNorm2d[bn1]\n",
      "  %143 : Float(10, 128, 28, 28) = onnx::Relu(%142), scope: ResNet/Sequential[layer2]/BasicBlock[0]/ReLU[relu]\n",
      "  %144 : Float(10, 128, 28, 28) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%143, %37), scope: ResNet/Sequential[layer2]/BasicBlock[0]/Conv2d[conv2]\n",
      "  %145 : Float(10, 128, 28, 28) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%144, %38, %39, %40, %41), scope: ResNet/Sequential[layer2]/BasicBlock[0]/BatchNorm2d[bn2]\n",
      "  %146 : Float(10, 128, 28, 28) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%140, %43), scope: ResNet/Sequential[layer2]/BasicBlock[0]/Sequential[downsample]/Conv2d[0]\n",
      "  %147 : Float(10, 128, 28, 28) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%146, %44, %45, %46, %47), scope: ResNet/Sequential[layer2]/BasicBlock[0]/Sequential[downsample]/BatchNorm2d[1]\n",
      "  %148 : Float(10, 128, 28, 28) = onnx::Add(%145, %147), scope: ResNet/Sequential[layer2]/BasicBlock[0]\n",
      "  %149 : Float(10, 128, 28, 28) = onnx::Relu(%148), scope: ResNet/Sequential[layer2]/BasicBlock[0]/ReLU[relu]\n",
      "  %150 : Float(10, 128, 28, 28) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%149, %49), scope: ResNet/Sequential[layer2]/BasicBlock[1]/Conv2d[conv1]\n",
      "  %151 : Float(10, 128, 28, 28) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%150, %50, %51, %52, %53), scope: ResNet/Sequential[layer2]/BasicBlock[1]/BatchNorm2d[bn1]\n",
      "  %152 : Float(10, 128, 28, 28) = onnx::Relu(%151), scope: ResNet/Sequential[layer2]/BasicBlock[1]/ReLU[relu]\n",
      "  %153 : Float(10, 128, 28, 28) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%152, %55), scope: ResNet/Sequential[layer2]/BasicBlock[1]/Conv2d[conv2]\n",
      "  %154 : Float(10, 128, 28, 28) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%153, %56, %57, %58, %59), scope: ResNet/Sequential[layer2]/BasicBlock[1]/BatchNorm2d[bn2]\n",
      "  %155 : Float(10, 128, 28, 28) = onnx::Add(%154, %149), scope: ResNet/Sequential[layer2]/BasicBlock[1]\n",
      "  %156 : Float(10, 128, 28, 28) = onnx::Relu(%155), scope: ResNet/Sequential[layer2]/BasicBlock[1]/ReLU[relu]\n",
      "  %157 : Float(10, 256, 14, 14) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%156, %61), scope: ResNet/Sequential[layer3]/BasicBlock[0]/Conv2d[conv1]\n",
      "  %158 : Float(10, 256, 14, 14) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%157, %62, %63, %64, %65), scope: ResNet/Sequential[layer3]/BasicBlock[0]/BatchNorm2d[bn1]\n",
      "  %159 : Float(10, 256, 14, 14) = onnx::Relu(%158), scope: ResNet/Sequential[layer3]/BasicBlock[0]/ReLU[relu]\n",
      "  %160 : Float(10, 256, 14, 14) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%159, %67), scope: ResNet/Sequential[layer3]/BasicBlock[0]/Conv2d[conv2]\n",
      "  %161 : Float(10, 256, 14, 14) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%160, %68, %69, %70, %71), scope: ResNet/Sequential[layer3]/BasicBlock[0]/BatchNorm2d[bn2]\n",
      "  %162 : Float(10, 256, 14, 14) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%156, %73), scope: ResNet/Sequential[layer3]/BasicBlock[0]/Sequential[downsample]/Conv2d[0]\n",
      "  %163 : Float(10, 256, 14, 14) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%162, %74, %75, %76, %77), scope: ResNet/Sequential[layer3]/BasicBlock[0]/Sequential[downsample]/BatchNorm2d[1]\n",
      "  %164 : Float(10, 256, 14, 14) = onnx::Add(%161, %163), scope: ResNet/Sequential[layer3]/BasicBlock[0]\n",
      "  %165 : Float(10, 256, 14, 14) = onnx::Relu(%164), scope: ResNet/Sequential[layer3]/BasicBlock[0]/ReLU[relu]\n",
      "  %166 : Float(10, 256, 14, 14) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%165, %79), scope: ResNet/Sequential[layer3]/BasicBlock[1]/Conv2d[conv1]\n",
      "  %167 : Float(10, 256, 14, 14) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%166, %80, %81, %82, %83), scope: ResNet/Sequential[layer3]/BasicBlock[1]/BatchNorm2d[bn1]\n",
      "  %168 : Float(10, 256, 14, 14) = onnx::Relu(%167), scope: ResNet/Sequential[layer3]/BasicBlock[1]/ReLU[relu]\n",
      "  %169 : Float(10, 256, 14, 14) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%168, %85), scope: ResNet/Sequential[layer3]/BasicBlock[1]/Conv2d[conv2]\n",
      "  %170 : Float(10, 256, 14, 14) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%169, %86, %87, %88, %89), scope: ResNet/Sequential[layer3]/BasicBlock[1]/BatchNorm2d[bn2]\n",
      "  %171 : Float(10, 256, 14, 14) = onnx::Add(%170, %165), scope: ResNet/Sequential[layer3]/BasicBlock[1]\n",
      "  %172 : Float(10, 256, 14, 14) = onnx::Relu(%171), scope: ResNet/Sequential[layer3]/BasicBlock[1]/ReLU[relu]\n",
      "  %173 : Float(10, 512, 7, 7) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%172, %91), scope: ResNet/Sequential[layer4]/BasicBlock[0]/Conv2d[conv1]\n",
      "  %174 : Float(10, 512, 7, 7) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%173, %92, %93, %94, %95), scope: ResNet/Sequential[layer4]/BasicBlock[0]/BatchNorm2d[bn1]\n",
      "  %175 : Float(10, 512, 7, 7) = onnx::Relu(%174), scope: ResNet/Sequential[layer4]/BasicBlock[0]/ReLU[relu]\n",
      "  %176 : Float(10, 512, 7, 7) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%175, %97), scope: ResNet/Sequential[layer4]/BasicBlock[0]/Conv2d[conv2]\n",
      "  %177 : Float(10, 512, 7, 7) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%176, %98, %99, %100, %101), scope: ResNet/Sequential[layer4]/BasicBlock[0]/BatchNorm2d[bn2]\n",
      "  %178 : Float(10, 512, 7, 7) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%172, %103), scope: ResNet/Sequential[layer4]/BasicBlock[0]/Sequential[downsample]/Conv2d[0]\n",
      "  %179 : Float(10, 512, 7, 7) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%178, %104, %105, %106, %107), scope: ResNet/Sequential[layer4]/BasicBlock[0]/Sequential[downsample]/BatchNorm2d[1]\n",
      "  %180 : Float(10, 512, 7, 7) = onnx::Add(%177, %179), scope: ResNet/Sequential[layer4]/BasicBlock[0]\n",
      "  %181 : Float(10, 512, 7, 7) = onnx::Relu(%180), scope: ResNet/Sequential[layer4]/BasicBlock[0]/ReLU[relu]\n",
      "  %182 : Float(10, 512, 7, 7) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%181, %109), scope: ResNet/Sequential[layer4]/BasicBlock[1]/Conv2d[conv1]\n",
      "  %183 : Float(10, 512, 7, 7) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%182, %110, %111, %112, %113), scope: ResNet/Sequential[layer4]/BasicBlock[1]/BatchNorm2d[bn1]\n",
      "  %184 : Float(10, 512, 7, 7) = onnx::Relu(%183), scope: ResNet/Sequential[layer4]/BasicBlock[1]/ReLU[relu]\n",
      "  %185 : Float(10, 512, 7, 7) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%184, %115), scope: ResNet/Sequential[layer4]/BasicBlock[1]/Conv2d[conv2]\n",
      "  %186 : Float(10, 512, 7, 7) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%185, %116, %117, %118, %119), scope: ResNet/Sequential[layer4]/BasicBlock[1]/BatchNorm2d[bn2]\n",
      "  %187 : Float(10, 512, 7, 7) = onnx::Add(%186, %181), scope: ResNet/Sequential[layer4]/BasicBlock[1]\n",
      "  %188 : Float(10, 512, 7, 7) = onnx::Relu(%187), scope: ResNet/Sequential[layer4]/BasicBlock[1]/ReLU[relu]\n",
      "  %189 : Dynamic = onnx::Pad[mode=\"constant\", pads=[0, 0, 0, 0, 0, 0, 0, 0], value=0](%188), scope: ResNet/AvgPool2d[avgpool]\n",
      "  %190 : Float(10, 512, 1, 1) = onnx::AveragePool[kernel_shape=[7, 7], pads=[0, 0, 0, 0], strides=[1, 1]](%189), scope: ResNet/AvgPool2d[avgpool]\n",
      "  %191 : Long() = onnx::Constant[value={0}]()\n",
      "  %192 : Dynamic = onnx::Shape(%190), scope: ResNet\n",
      "  %193 : Long() = onnx::Gather[axis=0](%192, %191), scope: ResNet\n",
      "  %194 : Long() = onnx::Constant[value={-1}]()\n",
      "  %195 : Dynamic = onnx::Unsqueeze[axes=[0]](%193), scope: ResNet\n",
      "  %196 : Dynamic = onnx::Unsqueeze[axes=[0]](%194), scope: ResNet\n",
      "  %197 : int[] = onnx::Concat[axis=0](%195, %196), scope: ResNet\n",
      "  %198 : Float(10, 512) = onnx::Reshape(%190, %197), scope: ResNet\n",
      "  %199 : Dynamic = onnx::Constant[value={0}]()\n",
      "  %200 : Dynamic = onnx::Gemm[alpha=1, beta=0, transB=1](%198, %121, %199)\n",
      "  %201 : Float(10, 1000) = onnx::Add(%122, %200)\n",
      "  return (%201);\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if not os.path.isdir(\"model\"):\n",
    "    os.mkdir(\"model\")\n",
    "\n",
    "model_name = \"pytorch_resnet.onnx\"\n",
    "model_path = os.path.join(\"model\", model_name)\n",
    "torch.onnx.export(net, \n",
    "                  dummy_input, \n",
    "                  model_path, \n",
    "                  verbose=True,\n",
    "                  export_params=True\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the ONNX model to Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/onnx_tf/common/__init__.py:87: UserWarning: FrontendHandler.get_outputs_names is deprecated. It will be removed in future release.. Use node.outputs instead.\n",
      "  warnings.warn(message)\n",
      "/usr/local/lib/python3.5/dist-packages/onnx_tf/common/handler_helper.py:73: UserWarning: Unknown op Acosh in domain `ai.onnx`.\n",
      "  handler.ONNX_OP, handler.DOMAIN or \"ai.onnx\"))\n",
      "/usr/local/lib/python3.5/dist-packages/onnx_tf/common/handler_helper.py:73: UserWarning: Unknown op Sinh in domain `ai.onnx`.\n",
      "  handler.ONNX_OP, handler.DOMAIN or \"ai.onnx\"))\n",
      "/usr/local/lib/python3.5/dist-packages/onnx_tf/common/handler_helper.py:73: UserWarning: Unknown op Asinh in domain `ai.onnx`.\n",
      "  handler.ONNX_OP, handler.DOMAIN or \"ai.onnx\"))\n",
      "/usr/local/lib/python3.5/dist-packages/onnx_tf/common/handler_helper.py:73: UserWarning: Unknown op Cosh in domain `ai.onnx`.\n",
      "  handler.ONNX_OP, handler.DOMAIN or \"ai.onnx\"))\n",
      "/usr/local/lib/python3.5/dist-packages/onnx_tf/common/handler_helper.py:73: UserWarning: Unknown op EyeLike in domain `ai.onnx`.\n",
      "  handler.ONNX_OP, handler.DOMAIN or \"ai.onnx\"))\n",
      "/usr/local/lib/python3.5/dist-packages/onnx_tf/common/handler_helper.py:73: UserWarning: Unknown op Atanh in domain `ai.onnx`.\n",
      "  handler.ONNX_OP, handler.DOMAIN or \"ai.onnx\"))\n",
      "/usr/local/lib/python3.5/dist-packages/onnx_tf/common/handler_helper.py:73: UserWarning: Unknown op Compress in domain `ai.onnx`.\n",
      "  handler.ONNX_OP, handler.DOMAIN or \"ai.onnx\"))\n",
      "/usr/local/lib/python3.5/dist-packages/onnx_tf/common/handler_helper.py:73: UserWarning: Unknown op DynamicSlice in domain `ai.onnx`.\n",
      "  handler.ONNX_OP, handler.DOMAIN or \"ai.onnx\"))\n",
      "/usr/local/lib/python3.5/dist-packages/onnx_tf/common/handler_helper.py:73: UserWarning: Unknown op ConstantLike in domain `ai.onnx`.\n",
      "  handler.ONNX_OP, handler.DOMAIN or \"ai.onnx\"))\n",
      "/usr/local/lib/python3.5/dist-packages/onnx_tf/handlers/backend/pool_mixin.py:124: UserWarning: Using the pooling op in compatibility mode.This means your graph cannot be serialized.Please configure your pooling operation to only use paddings that correspond to Tensorflow SAME or VALID padding.\n",
      "  \"correspond to Tensorflow SAME or VALID padding.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/onnx_tf/handlers/backend/reshape.py:31: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "\n",
    "# Load the ONNX file\n",
    "model = onnx.load(\"model/pytorch_resnet.onnx\")\n",
    "\n",
    "# Import the ONNX model to Tensorflow\n",
    "tf_rep = prepare(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported model has been executed on TF backend, and the result looks good!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "tf_out = tf_rep.run(dummy_input.numpy())\n",
    "torch_out = net(dummy_input).detach().numpy()\n",
    "\n",
    "np.testing.assert_almost_equal(tf_out[0], \n",
    "                               torch_out, \n",
    "                               decimal=3\n",
    "                              )\n",
    "\n",
    "print(\"Exported model has been executed on TF backend, and the result looks good!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
