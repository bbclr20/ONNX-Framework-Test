{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch-Alexnet-ONNX-Caffe2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use PyTorch pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import os\n",
    "\n",
    "# Use an existing model from Torchvision, note it \n",
    "# will download this if not already on your computer (might take time)\n",
    "net = models.alexnet(pretrained=True)\n",
    "net.eval()\n",
    "\n",
    "# Create some sample input in the shape this model expects\n",
    "dummy_input = torch.ones(10, 3, 224, 224)\n",
    "\n",
    "# # It's optional to label the input and output layers\n",
    "# input_names = [ \"actual_input_1\" ] + [ \"learned_%d\" % i for i in range(16) ]\n",
    "# output_names = [ \"output1\" ]\n",
    "\n",
    "# # Use the exporter from torch to convert to onnx \n",
    "# # model (that has the weights and net arch)\n",
    "# model_path = os.path.join(\"model\", model_name)\n",
    "# torch.onnx.export(model, dummy_input, model_path, verbose=True, input_names=input_names, output_names=output_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%0 : Float(10, 3, 224, 224)\n",
      "      %1 : Float(64, 3, 11, 11)\n",
      "      %2 : Float(64)\n",
      "      %3 : Float(192, 64, 5, 5)\n",
      "      %4 : Float(192)\n",
      "      %5 : Float(384, 192, 3, 3)\n",
      "      %6 : Float(384)\n",
      "      %7 : Float(256, 384, 3, 3)\n",
      "      %8 : Float(256)\n",
      "      %9 : Float(256, 256, 3, 3)\n",
      "      %10 : Float(256)\n",
      "      %11 : Float(4096, 9216)\n",
      "      %12 : Float(4096)\n",
      "      %13 : Float(4096, 4096)\n",
      "      %14 : Float(4096)\n",
      "      %15 : Float(1000, 4096)\n",
      "      %16 : Float(1000)) {\n",
      "  %17 : Float(10, 64, 55, 55) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[11, 11], pads=[2, 2, 2, 2], strides=[4, 4]](%0, %1, %2), scope: AlexNet/Sequential[features]/Conv2d[0]\n",
      "  %18 : Float(10, 64, 55, 55) = onnx::Relu(%17), scope: AlexNet/Sequential[features]/ReLU[1]\n",
      "  %19 : Float(10, 64, 27, 27) = onnx::MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%18), scope: AlexNet/Sequential[features]/MaxPool2d[2]\n",
      "  %20 : Float(10, 192, 27, 27) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1]](%19, %3, %4), scope: AlexNet/Sequential[features]/Conv2d[3]\n",
      "  %21 : Float(10, 192, 27, 27) = onnx::Relu(%20), scope: AlexNet/Sequential[features]/ReLU[4]\n",
      "  %22 : Float(10, 192, 13, 13) = onnx::MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%21), scope: AlexNet/Sequential[features]/MaxPool2d[5]\n",
      "  %23 : Float(10, 384, 13, 13) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%22, %5, %6), scope: AlexNet/Sequential[features]/Conv2d[6]\n",
      "  %24 : Float(10, 384, 13, 13) = onnx::Relu(%23), scope: AlexNet/Sequential[features]/ReLU[7]\n",
      "  %25 : Float(10, 256, 13, 13) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%24, %7, %8), scope: AlexNet/Sequential[features]/Conv2d[8]\n",
      "  %26 : Float(10, 256, 13, 13) = onnx::Relu(%25), scope: AlexNet/Sequential[features]/ReLU[9]\n",
      "  %27 : Float(10, 256, 13, 13) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%26, %9, %10), scope: AlexNet/Sequential[features]/Conv2d[10]\n",
      "  %28 : Float(10, 256, 13, 13) = onnx::Relu(%27), scope: AlexNet/Sequential[features]/ReLU[11]\n",
      "  %29 : Float(10, 256, 6, 6) = onnx::MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%28), scope: AlexNet/Sequential[features]/MaxPool2d[12]\n",
      "  %30 : Long() = onnx::Constant[value={0}]()\n",
      "  %31 : Dynamic = onnx::Shape(%29), scope: AlexNet\n",
      "  %32 : Long() = onnx::Gather[axis=0](%31, %30), scope: AlexNet\n",
      "  %33 : Long() = onnx::Constant[value={9216}]()\n",
      "  %34 : Dynamic = onnx::Unsqueeze[axes=[0]](%32), scope: AlexNet\n",
      "  %35 : Dynamic = onnx::Unsqueeze[axes=[0]](%33), scope: AlexNet\n",
      "  %36 : int[] = onnx::Concat[axis=0](%34, %35), scope: AlexNet\n",
      "  %37 : Float(10, 9216) = onnx::Reshape(%29, %36), scope: AlexNet\n",
      "  %38 : Float(10, 9216), %39 : Dynamic = onnx::Dropout[ratio=0.5](%37), scope: AlexNet/Sequential[classifier]/Dropout[0]\n",
      "  %40 : Dynamic = onnx::Constant[value={0}]()\n",
      "  %41 : Dynamic = onnx::Gemm[alpha=1, beta=0, transB=1](%38, %11, %40)\n",
      "  %42 : Float(10, 4096) = onnx::Add(%12, %41)\n",
      "  %43 : Float(10, 4096) = onnx::Relu(%42), scope: AlexNet/Sequential[classifier]/ReLU[2]\n",
      "  %44 : Float(10, 4096), %45 : Dynamic = onnx::Dropout[ratio=0.5](%43), scope: AlexNet/Sequential[classifier]/Dropout[3]\n",
      "  %46 : Dynamic = onnx::Constant[value={0}]()\n",
      "  %47 : Dynamic = onnx::Gemm[alpha=1, beta=0, transB=1](%44, %13, %46)\n",
      "  %48 : Float(10, 4096) = onnx::Add(%14, %47)\n",
      "  %49 : Float(10, 4096) = onnx::Relu(%48), scope: AlexNet/Sequential[classifier]/ReLU[5]\n",
      "  %50 : Dynamic = onnx::Constant[value={0}]()\n",
      "  %51 : Dynamic = onnx::Gemm[alpha=1, beta=0, transB=1](%49, %15, %50)\n",
      "  %52 : Float(10, 1000) = onnx::Add(%16, %51)\n",
      "  return (%52);\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if not os.path.isdir(\"model\"):\n",
    "    os.mkdir(\"model\")\n",
    "\n",
    "model_name = \"pytorch_alexnet.onnx\"\n",
    "model_path = os.path.join(\"model\", model_name)\n",
    "torch.onnx.export(net, \n",
    "                  dummy_input, \n",
    "                  model_path, \n",
    "                  verbose=True,\n",
    "                  export_params=True\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the ONNX model to Caffe2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import caffe2.python.onnx.backend as onnx_caffe2_backend\n",
    "\n",
    "# Load the ONNX ModelProto object. model is a standard Python protobuf object\n",
    "model = onnx.load(\"model/pytorch_alexnet.onnx\")\n",
    "\n",
    "# prepare the caffe2 backend for executing the model this converts the ONNX model into a\n",
    "# Caffe2 NetDef that can execute it. Other ONNX backends, like one for CNTK will be\n",
    "# availiable soon.\n",
    "c2_rep = onnx_caffe2_backend.prepare(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported model has been executed on Caffe2 backend, and the result looks good!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# run the model in Caffe2\n",
    "\n",
    "# Construct a map from input names to Tensor data.\n",
    "# The graph of the model itself contains inputs for all weight parameters, after the input image.\n",
    "# Since the weights are already embedded, we just need to pass the input image.\n",
    "# Set the first input.\n",
    "W = {model.graph.input[0].name: dummy_input.data.numpy()}\n",
    "\n",
    "# Run the Caffe2 net:\n",
    "c2_out = c2_rep.run(W)\n",
    "torch_out = net(dummy_input).detach().numpy()\n",
    "\n",
    "# Verify the numerical correctness upto 3 decimal places\n",
    "np.testing.assert_almost_equal(c2_out[0], \n",
    "                               torch_out, \n",
    "                               decimal=3\n",
    "                              )\n",
    "\n",
    "print(\"Exported model has been executed on Caffe2 backend, and the result looks good!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
